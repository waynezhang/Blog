---
layout: post
title: 『统计学习方法』阅读笔记
subtitle: 
date: 2017-03-06
author:     "Norris"
categories: blog
tags: [Statistic]
---


## Chapter 1 统计学习方法概论

统计学习的方法是基于数据构建统计模型从而对数据进行预测或分析，统计学习由监督学习、无监督学习、半监督学习、强化学习等组成。

监督学习的方法可以概括如下：

1. 假设数据由独立同分布的联合概率分布产生
2. 假设学习的模型属于某个假设空间，即所有可用模型的空间
3. 利用某个评价标准，从假设空间选取一个最优的模型，使它在测试数据样本下的效果最优
4. 最优模型的学习由算法实现

这其中包括了统计学习方法的三个要素：模型的假设空间；模型选择的标砖；模型学习的算法。简称为：模型；策略；算法。

监督学习中，所有输入的可能取值成为输入空间，输入空间通常由特征向量表示，所有特征向量存在的空间成为特征空间，输入空间有时候与特征空间不区分，有时候，需要将样本从输入空间映射到特征空间从而提取出其有用的特征（特征提取的过程十分重要，例如PCA、SVD等都可以看做输入空间到特征空间的映射）。

监督学习的输入到输出由一个映射来表示，这个映射就是我们所说的模型，模型可以分为概率模型以及非概率模型，通常由条件概率分布$$P(Y\|X)$$或者决策函数$$Y=f(X)$$表示。

模型如果过于复杂会导致过度拟合的问题存在，因此在模型选择时，需要能够符合奥卡姆剃刀的原则，规避过度拟合的方法就是正则化和交叉验证。正则化可以在损失函数中加入L1、L2范数，交叉验证通常使用K-折交叉验证。

模型最终的作用还是将已经训练好的模型来预测分析未知的数据集，而评估一个模型在未知数据集上的优秀与否需要泛化能力这个指标来表示。实际应用中，我们通常没有非常多的数据来验证泛化能力，所以我们通产以泛化误差上界来比较模型之间的泛化能力。泛化误差上界公式为：

$$R(f) \leq \widehat{R}(f)+\epsilon(d,N,\delta)$$

其中，$$R(f)$$是泛化误差，$$\widehat{R}(f)$$是模型估计的误差，$$\epsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(logd+log\frac{1}{\delta})}$$